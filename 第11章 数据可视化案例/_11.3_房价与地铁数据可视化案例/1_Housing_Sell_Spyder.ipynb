{
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": 3
        },
        "orig_nbformat": 2
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# https://www.jianshu.com/p/ecf3a88d9ae1\n",
                "# https://zhuanlan.zhihu.com/p/28059182\n",
                "import urllib.request\n",
                "from lxml import etree\n",
                "import pandas as pd\n",
                "#from openpyxl import Workbook\n",
                "\n",
                "\n",
                "# 获取并解码网页\n",
                "def get_htmltext(url):\n",
                "    html = urllib.request.urlopen(url)\n",
                "    htmltext = html.read().decode('utf-8')\n",
                "    return htmltext\n",
                "\n",
                "\n",
                "def get_data(htmltext, total):\n",
                "    html = etree.HTML(htmltext)  # 使用lxml库将获取的网页内容解析\n",
                "    # 将包含所有房屋的代码块提取出来，每个房屋的信息都是在<li class=\"clear\">这个标签下面\n",
                "    houses = html.xpath('//ul[@class=\"sellListContent\"]/li')\n",
                "    # /html/body/div[4]/div[1]/ul/li[1]\n",
                "    # body > div.content > div.leftContent > ul > li:nth-child(1)\n",
                "    for house in houses:  # 迭代，将每个房屋各方面的信息提取出来\n",
                "        house_info = {}  # 新建一个字典用于存放单个房屋的信息\n",
                "        try:  # 抽取各个方面信息#\n",
                "            house_info['title'] = house.xpath('.//div[1]/div[1]/a/text()')[0]\n",
                "            house_info['addressinfo'] = house.xpath(\n",
                "                './/div[1]/div[2]/div/a/text()')[0]\n",
                "            # /html/body/div[4]/div[1]/ul/li[1]/div[1]/div[2]/div/a\n",
                "            house_info['sizeinfo'] = house.xpath(\n",
                "                './/div[1]/div[2]/div/text()')[0]\n",
                "            # /html/body/div[4]/div[1]/ul/li[1]/div[1]/div[2]/div/text()\n",
                "            #house_info['flood']=house.xpath('./div[@class=\"info clear\"]/div[@class=\"flood\"]/div/text()')[0]\n",
                "\n",
                "            house_info['followinfo'] = house.xpath(\n",
                "                './/div[1]/div[3]/div/text()')[0]\n",
                "            # /html/body/div[4]/div[1]/ul/li[1]/div[1]/div[3]/div\n",
                "            house_info['total_price'] = house.xpath(\n",
                "                './/div[1]/div[6]/div[1]/span/text()')[0]\n",
                "            # /html/body/div[4]/div[1]/ul/li[1]/div[1]/div[6]/div[1]/span\n",
                "            house_info['unit_price'] = house.xpath(\n",
                "                './/div[1]/div[6]/div[2]/span/text()')[0]\n",
                "            # /html/body/div[4]/div[1]/ul/li[1]/div[1]/div[6]/div[2]/span\n",
                "            total.append(house_info)  # 将单个房屋的信息放入总列表中\n",
                "        except:  # try，避免某方面信息缺失导致报错\n",
                "            continue\n",
                "    print('正在爬取第%d页' % i)\n",
                "\n",
                "# 下面这块代码是用来将解析后的网页内容导出保存，方便查找信息所在的路径\n",
                "#string=etree.tostring(html, encoding='utf-8', pretty_print=True, method='html')\n",
                "# handle=open(r'E:\\test1\\text.txt','w',encoding='utf-8')\n",
                "# handle.write(string.decode('utf-8'))\n",
                "\n",
                "\n",
                "# 运行起来\n",
                "total = []\n",
                "house_info = {}  # 新建一个字典用于存放单个房屋的信息\n",
                "house_info['title'] = 'title'\n",
                "house_info['addressinfo'] = 'addressinfo'\n",
                "house_info['sizeinfo'] = 'sizeinfo'\n",
                "# house_info['flood']='flood'\n",
                "house_info['followinfo'] = 'followinfo'\n",
                "house_info['total_price'] = 'total_price'\n",
                "house_info['unit_price'] = 'unit_price'\n",
                "total.append(house_info)\n",
                "for i in range(0, 1):\n",
                "    # https://cd.lianjia.com/ershoufang/pg%d/\n",
                "    url = 'https://sz.lianjia.com/ershoufang/pg%d/' % i\n",
                "    htmltext = get_htmltext(url)\n",
                "    get_data(htmltext, total)\n",
                "\n",
                "# 将结果放进空的DataFrame里面，方便使用pandas库对内容汇总处理。\n",
                "# df=pd.DataFrame(total)\n",
                "\n",
                "my_df = pd.DataFrame(total)\n",
                "my_df.to_csv('ShenzhenHousing_Price.csv', index=False, header=False)\n",
                "\n",
                "my_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ]
}